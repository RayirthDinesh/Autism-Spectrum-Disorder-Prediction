{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ckw4Zu_9KP_e",
        "eul7Ap1sKa5Z",
        "B7p3hq8aKjrS",
        "LMZXoRsoKoo7"
      ],
      "toc_visible": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RayirthDinesh/Autism-Spectrum-Disorder-Prediction/blob/main/ASDPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "sSKpYgFDJ-zI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmoF7uIsyB7A"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from keras.regularizers import l2\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "UfD65Tq5KELC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading data\n",
        "\n",
        "#https://www.kaggle.com/competitions/autismdiagnosis/data - Download train.csv\n",
        "\n",
        "# Construct the direct download URL\n",
        "url = \"https://raw.githubusercontent.com/RayirthDinesh/Autism-Spectrum-Disorder-Prediction/refs/heads/main/train.csv\"\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "autism_data = pd.read_csv(url)\n",
        "\n"
      ],
      "metadata": {
        "id": "yviuHOmrzi9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collect information about the data**\n",
        "\n",
        "\n",
        "1.   Check for number of samples and features\n",
        "2.   Number of Null Values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4NoggCrQbAHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of samples (rows)\n",
        "num_samples = autism_data.shape[0]\n",
        "\n",
        "# Get the number of features (columns)\n",
        "num_features = autism_data.shape[1]\n",
        "\n",
        "print(f'The dataset has {num_samples} samples and {num_features} features.')\n",
        "autism_data.head()"
      ],
      "metadata": {
        "id": "areO_zv10Sqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for null values\n",
        "autism_data.info()"
      ],
      "metadata": {
        "id": "caNziG2AwiO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for statistical measure of the dataset\n",
        "autism_data.describe().T"
      ],
      "metadata": {
        "id": "CBw87ceEw5i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#value counts on categorical columns\n",
        "print('*** Relation ***')\n",
        "print(autism_data['relation'].value_counts())\n",
        "\n",
        "print('\\n\\n*** Ethnicity ***')\n",
        "print(autism_data['ethnicity'].value_counts())\n",
        "\n",
        "print('\\n\\n*** Jaundice ***')\n",
        "print(autism_data['jaundice'].value_counts())\n",
        "\n",
        "print('\\n\\n*** Austim ***')\n",
        "print(autism_data['austim'].value_counts())\n",
        "\n",
        "print('\\n\\n*** Gender ***')\n",
        "print(autism_data['gender'].value_counts())\n",
        "\n",
        "print('\\n\\n*** Country of Residence ***')\n",
        "print(autism_data['contry_of_res'].value_counts())\n",
        "\n",
        "print('\\n\\n*** Used App Before ***')\n",
        "print(autism_data['used_app_before'].value_counts())"
      ],
      "metadata": {
        "id": "pBylUl0VxJkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "8yGDsgFwKJ06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess data**\n",
        "1. Convert categorical features to numerical\n",
        "2. Run PCA to remove feature space\n",
        "3. Remove ID column - unique for each row"
      ],
      "metadata": {
        "id": "kugJnNgkbf2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical features to numerical\n",
        "def preprocess_data(data, categorical_features):\n",
        "    le = LabelEncoder()\n",
        "    for feature in categorical_features:\n",
        "        data[feature] = le.fit_transform(data[feature])\n",
        "    return data\n",
        "\n",
        "categorical_features = [\n",
        "    'gender', 'ethnicity', 'jaundice', 'austim',\n",
        "    'contry_of_res', 'used_app_before', 'age_desc', 'relation'\n",
        "]\n",
        "\n",
        "#gender: f = 0, m = 1\n",
        "#ethnicity = (need to sort more approiately in case test has ethnicity that isn't listed in the dataset)\n",
        "#jaundice = no = 0, yes = 1\n",
        "#austim = no = 0, yes = 1\n",
        "#contry_of_res = (need to sort more approiately in case test has ethnicity that isn't listed in the dataset)\n",
        "#used_app_before = no = 0, yes = 1\n",
        "#age_desc = 18 and more = 0 (all values are 0)\n",
        "#relation = ? = 0, Health care professional = 1, Others = 2, Parent = 3, Relative = 4, self = 5\n",
        "\n",
        "autism_data['ethnicity'].replace({'?': 'Others', 'others': 'Others'}, inplace=True)\n",
        "autism_data = preprocess_data(autism_data, categorical_features)\n",
        "\n",
        "autism_data.head()"
      ],
      "metadata": {
        "id": "rFw-9P1oYKvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run PCA\n",
        "def runPCA():\n",
        "  features = autism_data.columns\n",
        "  x = autism_data.loc[:, features].values\n",
        "  x = StandardScaler().fit_transform(x)\n",
        "\n",
        "  #Code to determine elbow point (at 22)\n",
        "  pca = PCA().fit(x)\n",
        "  plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "  plt.xlabel('Number of Components')\n",
        "  plt.ylabel('Cumulative Explained Variance')\n",
        "  plt.xticks(np.arange(1, len(pca.explained_variance_ratio_) + 1, 1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "runPCA()"
      ],
      "metadata": {
        "id": "gbxCy7Vx-IcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Features correlation with the Class/ASD\n",
        "corr = autism_data.corr()\n",
        "\n",
        "# Extract the correlation with the target variable\n",
        "target_corr = corr[['Class/ASD']]\n",
        "\n",
        "# Convert to DataFrame for heatmap\n",
        "\n",
        "# Heatmap of correlation between each feature and Class/ASD\n",
        "plt.figure(figsize=(5, 8))\n",
        "sns.heatmap(target_corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation with Target Variable')\n",
        "plt.show()\n",
        "\n",
        "#Based on graph the most correlated features are A3_Score, A6_Score, A9_Score and the least correlated is gender and used_app_before"
      ],
      "metadata": {
        "id": "xPNw9T-c95CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove columns that aren't useful\n",
        "\n",
        "#Remove ID Column - unique on each row\n",
        "autism_data = autism_data.drop(columns=['ID'])\n",
        "\n",
        "# age_desc is always \"18 and more\"\n",
        "autism_data = autism_data.drop(columns=['age_desc'])\n",
        "\n",
        "#Very low correlation (from the heatmap)\n",
        "autism_data = autism_data.drop(columns=['used_app_before'])\n",
        "\n",
        "runPCA()"
      ],
      "metadata": {
        "id": "d3rF9Qs-D0yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtain final X and Y vectors and split train and test data**"
      ],
      "metadata": {
        "id": "XFN_Qta7-eqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude the target variable from the original features\n",
        "final_X = autism_data.drop(columns=['Class/ASD'])\n",
        "\n",
        "#final y vector with the labels for each of the samples\n",
        "final_Y = autism_data['Class/ASD']\n",
        "\n",
        "# Spliting dataset into training and testing sections using the train_test_split function.\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(final_X, final_Y, test_size=0.15, random_state=23)"
      ],
      "metadata": {
        "id": "-_WnHXW6CbGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "Ckw4Zu_9KP_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization**\n",
        "\n",
        "Includes:\n",
        "1.   Gender distribution with Class/ASD\n",
        "2.   Jaundice distribution with Class/ASD\n",
        "3.   Austim distribution with Class/ASD\n",
        "4.   Heatmap correlation of each feature with Class/ASD\n",
        "5.   Heatmap correalation of each feature and target with each other\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QDT263rVaIdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gender and Class/ASD distribution\n",
        "sns.barplot(x='gender', y='Class/ASD', hue='gender', data = autism_data)"
      ],
      "metadata": {
        "id": "6XgYrMHB14Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Jaundice and Class/ASD distribution\n",
        "sns.barplot(x='jaundice', y='Class/ASD', hue='jaundice', data = autism_data)"
      ],
      "metadata": {
        "id": "8wuC9mJzUOog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#austim and Class/ASD distribution\n",
        "sns.barplot(x='austim', y='Class/ASD', hue= 'austim', data = autism_data)"
      ],
      "metadata": {
        "id": "XcooTJ-yZy8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cofounding: Features correlation with each other\n",
        "# Heatmap of correlation between each feature\n",
        "corr = autism_data.corr()\n",
        "plt.figure(figsize=(20, 15))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A1zCOKOBiS8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "8kSG2eNmKVBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Model #1: Logistic regression**"
      ],
      "metadata": {
        "id": "mWtSIQ1LS6nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the logistic regression model\n",
        "log_reg = LogisticRegression(solver='lbfgs',max_iter=1000,random_state=23)\n",
        "\n",
        "# Fit the model on the training data\n",
        "log_reg.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_log = log_reg.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_log))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_log))\n",
        "\n",
        "scorelog = accuracy_score(test_Y, pred_Y_log)\n",
        "print('Logistic Regression Model Accuracy: {:.2%}'.format(scorelog))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_log = log_reg.predict_proba(test_X)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_Y, pred_prob_log, pos_label=log_reg.classes_[1])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Check feature importance for logistic regression\n",
        "rfe = RFE(estimator=LogisticRegression(solver='lbfgs',max_iter=1000, random_state=23), n_features_to_select=1, step=1)\n",
        "rfe = rfe.fit(train_X, train_Y)\n",
        "ranking = rfe.ranking_\n",
        "\n",
        "feature_names = train_X.columns\n",
        "print(\" \")\n",
        "for rank, feature in sorted(zip(ranking, feature_names)):\n",
        "    print(f\"Feature: {feature}, Rank: {rank}\")\n",
        "print(\" \")"
      ],
      "metadata": {
        "id": "x62iUB76S_rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model #2: Random Forest**"
      ],
      "metadata": {
        "id": "i_mFtAmeYC7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, random_state=23)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf_clf.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_rf = rf_clf.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_rf))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_rf))\n",
        "\n",
        "scorerf = accuracy_score(test_Y, pred_Y_rf)\n",
        "print('Random Forest Model Accuracy: {:.2%}'.format(scorerf))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_rf = rf_clf.predict_proba(test_X)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_Y, pred_prob_rf, pos_label=rf_clf.classes_[1])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "#Display feature importance for random forest\n",
        "rfe_rf = RFE(estimator= RandomForestClassifier(), n_features_to_select=1, step=1)\n",
        "rfe_rf = rfe_rf.fit(train_X, train_Y)\n",
        "ranking = rfe_rf.ranking_\n",
        "\n",
        "feature_names = train_X.columns\n",
        "print(\" \")\n",
        "for rank, feature in sorted(zip(ranking, feature_names)):\n",
        "    print(f\"Feature: {feature}, Rank: {rank}\")\n",
        "print(\" \")"
      ],
      "metadata": {
        "id": "Tifpx3ZsYKfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model #3: SVM (Support Vector Machine)**"
      ],
      "metadata": {
        "id": "T0ATlmfE_i9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SVM classifier\n",
        "svm_clf = SVC(kernel='linear', probability=True,  random_state=23)\n",
        "\n",
        "# Fit the model on the training data\n",
        "svm_clf.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_svm = svm_clf.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_svm))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_svm))\n",
        "\n",
        "scoresvm = accuracy_score(test_Y, pred_Y_svm)\n",
        "print('SVM (Support Vector Machine) Model Accuracy: {:.2%}'.format(scoresvm))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_svm = svm_clf.predict_proba(test_X)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_Y, pred_prob_svm, pos_label=svm_clf.classes_[1])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "#Display feature importance for SVM\n",
        "rfe_svm = RFE(estimator=SVC(kernel='linear'), n_features_to_select=1, step=1)\n",
        "rfe_svm = rfe_svm.fit(train_X, train_Y)\n",
        "ranking = rfe_svm.ranking_\n",
        "\n",
        "feature_names = train_X.columns\n",
        "print(\" \")\n",
        "for rank, feature in sorted(zip(ranking, feature_names)):\n",
        "    print(f\"Feature: {feature}, Rank: {rank}\")\n",
        "print(\" \")"
      ],
      "metadata": {
        "id": "YJhy41cN_wJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model #4: Decision trees**"
      ],
      "metadata": {
        "id": "uIT2dFrBRMV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision Trees classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=23)\n",
        "\n",
        "# Fit the model on the training data\n",
        "dt_clf.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_dt = dt_clf.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_dt))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_dt))\n",
        "\n",
        "scoredt = accuracy_score(test_Y, pred_Y_dt)\n",
        "print('Decision Trees Model Accuracy: {:.2%}'.format(scoredt))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_dt = dt_clf.predict_proba(test_X)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_Y, pred_prob_dt, pos_label=dt_clf.classes_[1])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4ACbT5G6RYc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model #5: Ridge Classifier**"
      ],
      "metadata": {
        "id": "FGmKTO9-YqSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Ridge classifier\n",
        "r_clf = RidgeClassifier(random_state=23)\n",
        "\n",
        "# Fit the model on the training data\n",
        "r_clf.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_r = r_clf.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_r))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_r))\n",
        "\n",
        "scorer = accuracy_score(test_Y, pred_Y_r)\n",
        "print('Ridge Classifier Model Accuracy: {:.2%}'.format(scorer))\n"
      ],
      "metadata": {
        "id": "uKVJOchMZDEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model #6: kNeighbors Classifier**"
      ],
      "metadata": {
        "id": "jSsiNEsrqCLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the  KNeighbors classifier\n",
        "kN_clf = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit the model on the training data\n",
        "kN_clf.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_KN = kN_clf.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_KN))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_KN))\n",
        "\n",
        "scoreKN = accuracy_score(test_Y, pred_Y_KN)\n",
        "print('KNeighbors Classifier Model Accuracy: {:.2%}'.format(scoreKN))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_kN = kN_clf.predict_proba(test_X)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_Y, pred_prob_kN, pos_label=kN_clf.classes_[1])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "#Display feature importance for kNeighbors classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "pipeline = Pipeline([\n",
        "    ('feature_selection', selector),\n",
        "    ('classification', knn_model)\n",
        "])\n",
        "\n",
        "pipeline.fit(train_X, train_Y)\n",
        "scores = selector.scores_\n",
        "feature_names = train_X.columns\n",
        "print(\"Feature Scores:\")\n",
        "for score, feature in sorted(zip(scores, feature_names), reverse=True):\n",
        "    print(f\"Feature: {feature}, Score: {score}\")\n",
        "print(\" \")"
      ],
      "metadata": {
        "id": "BGbT0ygvqL0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model #7: XG Boost**"
      ],
      "metadata": {
        "id": "X6KjtwbkSTmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the XGBoost classifier\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=200, random_state=23, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Fit the model on the training data\n",
        "xgb_clf.fit(train_X, train_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred_Y_xgb = xgb_clf.predict(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_Y, pred_Y_xgb))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_Y, pred_Y_xgb))\n",
        "\n",
        "scorexgb = accuracy_score(test_Y, pred_Y_xgb)\n",
        "print('xgBoost Classifier Model Accuracy: {:.2%}'.format(scorexgb))\n",
        "\n",
        "# Display ROC curve\n",
        "pred_prob_xgb = xgb_clf.predict_proba(test_X)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_Y, pred_prob_xgb, pos_label=xgb_clf.classes_[1])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "# Display feature importance for XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "pipeline = Pipeline([\n",
        "    ('feature_selection', selector),\n",
        "    ('classification', xgb_model)\n",
        "])\n",
        "\n",
        "pipeline.fit(train_X, train_Y)\n",
        "scores = selector.scores_\n",
        "feature_names = train_X.columns\n",
        "print(\"Feature Scores:\")\n",
        "for score, feature in sorted(zip(scores, feature_names), reverse=True):\n",
        "    print(f\"Feature: {feature}, Score: {score}\")\n",
        "print(\" \")\n",
        "\n"
      ],
      "metadata": {
        "id": "vAYwGggyIiNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average Accuracy of each Model"
      ],
      "metadata": {
        "id": "eul7Ap1sKa5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average Model Accuracy test:**"
      ],
      "metadata": {
        "id": "nBBcD6uBn4oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Take Average Accuracy of each of the 6 models\n",
        "#Initialize variables and lists\n",
        "\n",
        "ScoreAvgLog = 0\n",
        "ScoreAvgRF = 0\n",
        "ScoreAvgSVM = 0\n",
        "ScoreAvgDT = 0\n",
        "ScoreAvgR = 0\n",
        "ScoreAvgKN = 0\n",
        "ScoreAvgXGB = 0\n",
        "\n",
        "for i in range(15):\n",
        "    randomState = random.randint(1, 100)\n",
        "    train_X_test, test_X_test, train_Y_test, test_Y_test = train_test_split(final_X, final_Y, test_size=0.15, random_state=randomState)\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    train_X_test = scaler.fit_transform(train_X_test)\n",
        "    test_X_test = scaler.transform(test_X_test)\n",
        "\n",
        "    # Logistic Regression\n",
        "    log_reg_test = LogisticRegression(solver='liblinear', random_state=randomState, max_iter=1000)\n",
        "    log_reg_test.fit(train_X_test, train_Y_test)\n",
        "    pred_Y_log_test = log_reg_test.predict(test_X_test)\n",
        "    scorelog = accuracy_score(test_Y_test, pred_Y_log_test)\n",
        "    ScoreAvgLog += int(scorelog*100)\n",
        "\n",
        "    # Random Forest\n",
        "    rf_clf_test = RandomForestClassifier(n_estimators=200,  random_state=randomState)\n",
        "    rf_clf_test.fit(train_X_test, train_Y_test)\n",
        "    pred_Y_rf_test = rf_clf_test.predict(test_X_test)\n",
        "    scoreRF = accuracy_score(test_Y_test, pred_Y_rf_test)\n",
        "    ScoreAvgRF += int(scoreRF*100)\n",
        "\n",
        "    # SVM\n",
        "    svm_clf_test = SVC(kernel='linear',  random_state=randomState)\n",
        "    svm_clf_test.fit(train_X_test, train_Y_test)\n",
        "    pred_Y_svm_test = svm_clf_test.predict(test_X_test)\n",
        "    scoreSVM = accuracy_score(test_Y_test, pred_Y_svm_test)\n",
        "    ScoreAvgSVM += int(scoreSVM*100)\n",
        "\n",
        "    # Decision Tree\n",
        "    dt_clf_test = DecisionTreeClassifier(random_state=randomState)\n",
        "    dt_clf_test.fit(train_X_test, train_Y_test)\n",
        "    pred_Y_dt_test = dt_clf_test.predict(test_X_test)\n",
        "    scoreDT = accuracy_score(test_Y_test, pred_Y_dt_test)\n",
        "    ScoreAvgDT += int(scoreDT*100)\n",
        "\n",
        "    #Ridge Classifiwr\n",
        "    r_clf_test = RidgeClassifier(random_state=randomState)\n",
        "    r_clf_test.fit(train_X, train_Y)\n",
        "    pred_Y_r_test = r_clf_test.predict(test_X)\n",
        "    scoreR = accuracy_score(test_Y_test, pred_Y_r_test)\n",
        "    ScoreAvgR += int(scoreR*100)\n",
        "\n",
        "    #KNeighbors Classifier\n",
        "    kN_clf_test = KNeighborsClassifier(n_neighbors=3)\n",
        "    kN_clf_test.fit(train_X_test, train_Y_test)\n",
        "    pred_Y_KN_test = kN_clf_test.predict(test_X_test)\n",
        "    scoreKN = accuracy_score(test_Y_test, pred_Y_KN_test)\n",
        "    ScoreAvgKN += int(scoreKN*100)\n",
        "\n",
        "    #XG Boost\n",
        "    xgb_clf_test = xgb.XGBClassifier(n_estimators=200, random_state=23, use_label_encoder=False, eval_metric='logloss')\n",
        "    xgb_clf_test.fit(train_X_test, train_Y_test)\n",
        "    pred_Y_xgb_test = xgb_clf_test.predict(test_X_test)\n",
        "    scorexgb = accuracy_score(test_Y_test, pred_Y_xgb_test)\n",
        "    ScoreAvgXGB += int(scorexgb*100)\n",
        "\n",
        "#Print Results\n",
        "accuracies = {\n",
        "    'Random Forest': ScoreAvgRF / 1500,\n",
        "    'Logistic Regression': ScoreAvgLog / 1500,\n",
        "    'SVM': ScoreAvgSVM / 1500,\n",
        "    'Decision Tree': ScoreAvgDT / 1500,\n",
        "    'Ridge Classifier': ScoreAvgR / 1500,\n",
        "    'KN Classifier': ScoreAvgKN / 1500,\n",
        "    'XG Boost': ScoreAvgXGB / 1500\n",
        "}\n",
        "\n",
        "sorted_accuracies = sorted(accuracies.items(), key=lambda x: x[1], reverse=True)\n",
        "rank = 1\n",
        "for model, accuracy in sorted_accuracies:\n",
        "    print(str(rank) + \". \" + f'{model} Model Accuracy: {accuracy:.2%}')\n",
        "    rank+=1\n"
      ],
      "metadata": {
        "id": "Y7WGGezlvpZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks"
      ],
      "metadata": {
        "id": "B7p3hq8aKjrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sckit Neural Network Classification model:**"
      ],
      "metadata": {
        "id": "up05KXGyoREm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ScoresNN = []\n",
        "\n",
        "for i in range(5):\n",
        "  randomState = random.randint(1, 100)\n",
        "  X_trainNN, X_testNN, Y_trainNN, Y_testNN = train_test_split(final_X, final_Y, test_size=0.15, random_state=randomState)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_trainNN = scaler.fit_transform(X_trainNN)\n",
        "  X_testNN = scaler.transform(X_testNN)\n",
        "\n",
        "  modelNN = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, activation='relu', solver='adam', learning_rate_init=0.001, alpha=0.001, batch_size=10)\n",
        "\n",
        "  modelNN.fit(X_trainNN, Y_trainNN)\n",
        "  predictNN = modelNN.predict(X_testNN)\n",
        "\n",
        "  scoreNN = accuracy_score(Y_testNN, predictNN )\n",
        "  ScoresNN.append((int(scoreNN*100)))\n",
        "\n",
        "  #Display ROC curve\n",
        "  pred_prob_NN = modelNN.predict_proba(X_testNN)[:, 1]\n",
        "  fpr, tpr, _ = metrics.roc_curve(Y_testNN, pred_prob_NN)\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "  display.plot()\n",
        "  plt.show()\n",
        "\n",
        "average_accuracy = sum(ScoresNN) / len(ScoresNN)\n",
        "print(f'Average Accuracy: {average_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "3ounAuxMTmDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorFlow Neural Network Classification model:**"
      ],
      "metadata": {
        "id": "cnj2JZ6Lchs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ScoresNNtf = []\n",
        "\n",
        "for i in range(5):\n",
        "    randomState = random.randint(1, 100)\n",
        "    X_trainNNtf, X_testNNtf, Y_trainNNtf, Y_testNNtf = train_test_split(final_X, final_Y, test_size=0.15, random_state=randomState)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_trainNNtf = scaler.fit_transform(X_trainNNtf)\n",
        "    X_testNNtf = scaler.transform(X_testNNtf)\n",
        "\n",
        "    Y_trainNNtf = to_categorical(Y_trainNNtf)\n",
        "    Y_testNNtf = to_categorical(Y_testNNtf)\n",
        "\n",
        "    modelNNtf = Sequential()\n",
        "    modelNNtf.add(Dense(480, activation='relu', kernel_regularizer=l2(0.01), input_shape=(int(X_trainNNtf.shape[1]),)))\n",
        "    modelNNtf.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    modelNNtf.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    modelNNtf.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    modelNNtf.fit(X_trainNNtf, Y_trainNNtf, epochs=200, batch_size=10, verbose=0)\n",
        "    evaluate = modelNNtf.evaluate(X_testNNtf, Y_testNNtf)\n",
        "\n",
        "    ScoresNNtf.append(evaluate[1])\n",
        "\n",
        "    #Display ROC curve\n",
        "    pred_prob_NNtf = modelNNtf.predict(X_testNNtf)[:, 1]\n",
        "    fpr, tpr, _ = metrics.roc_curve(Y_testNNtf[:, 1], pred_prob_NNtf)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "    display.plot()\n",
        "    plt.show()\n",
        "\n",
        "average_accuracy = sum(ScoresNNtf) / len(ScoresNNtf)\n",
        "print(f'Average Accuracy: {average_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "rVdbafiUciUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Best Models w/ different Features"
      ],
      "metadata": {
        "id": "LMZXoRsoKoo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Models with only the test Scores**"
      ],
      "metadata": {
        "id": "jB7LkYkMWHgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new dataframe with only Autism test scores data (testing to see if it performs better with only cognitive scores)\n",
        "dfAutismScores = autism_data.iloc[:,:10]\n",
        "dfAutismScores.head()\n",
        "train_XScores, test_XScores, train_YScores, test_YScores = train_test_split(dfAutismScores, final_Y, test_size=0.15, random_state=23)"
      ],
      "metadata": {
        "id": "-8qkjTp_A4g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression with new dataframe\n",
        "\n",
        "log_regScores = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=23)\n",
        "log_regScores.fit(train_XScores, train_YScores)\n",
        "pred_Y_log_Scores = log_regScores.predict(test_XScores)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_YScores, pred_Y_log_Scores))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_YScores, pred_Y_log_Scores))\n",
        "\n",
        "scorelog_Scores = accuracy_score(test_YScores, pred_Y_log_Scores)\n",
        "print('Logistic Regression Model Accuracy: {:.2%}'.format(scorelog_Scores))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_logScores = log_regScores.predict_proba(test_XScores)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_YScores, pred_prob_logScores, pos_label=log_regScores.classes_[1])\n",
        "#roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YsmQiCmSB5Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest with new dataframe\n",
        "\n",
        "rf_clfScores = RandomForestClassifier(n_estimators=200, random_state=23)\n",
        "rf_clfScores.fit(train_XScores, train_YScores)\n",
        "pred_Y_rfScores = rf_clfScores.predict(test_XScores)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_YScores, pred_Y_rfScores))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_YScores, pred_Y_rfScores))\n",
        "\n",
        "scorerfScores = accuracy_score(test_YScores, pred_Y_rfScores)\n",
        "print('Random Forest Model Accuracy: {:.2%}'.format(scorerfScores))\n",
        "\n",
        "#Display ROC curve\n",
        "pred_prob_rfScores = rf_clfScores.predict_proba(test_XScores)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(test_YScores, pred_prob_rfScores, pos_label=rf_clfScores.classes_[1])\n",
        "#roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                                  estimator_name='processing estimator')\n",
        "display.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "huf7XHMlC1jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Having only Autism cognitive scores data yields worse results from the same models**"
      ],
      "metadata": {
        "id": "MN4jaNt1YmtZ"
      }
    }
  ]
}